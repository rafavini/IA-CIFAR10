{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Submissao final e relatorio.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3de0a167c0d043f5a3e598a01daf3389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd292daf8818461a8c963f73e20a7185",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_264f6c657bc0476a96661f69d0cb555d",
              "IPY_MODEL_a3e10f57c39b4ebdb9fff5d9e582ff14"
            ]
          }
        },
        "cd292daf8818461a8c963f73e20a7185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "264f6c657bc0476a96661f69d0cb555d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_5147356216c34fefbb1f93a7be215b2d",
            "_dom_classes": [],
            "description": "idx_ex",
            "step": 1,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 2000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1373,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 0,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a24bcec2c75c4f57ab0a68677b04238f"
          }
        },
        "a3e10f57c39b4ebdb9fff5d9e582ff14": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": [],
                  "needs_background": "light"
                },
                "image/png": "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\n",
                "text/plain": "<Figure size 144x144 with 1 Axes>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_31b87a3306054039912a7b5907843bb8",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "5147356216c34fefbb1f93a7be215b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a24bcec2c75c4f57ab0a68677b04238f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31b87a3306054039912a7b5907843bb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2168dd69efa4892a46dc2853c816071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8c93c72998534ebeb5a5be1ddc348287",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3476b0bef9534651b065334b363e794d",
              "IPY_MODEL_a58816bcb7234d3d996fb178c694fda9",
              "IPY_MODEL_8e9b6a5471164ae1ba2890e24caf8a31",
              "IPY_MODEL_279a9e26cf234d4ea2b9fde2432b40ab"
            ]
          }
        },
        "8c93c72998534ebeb5a5be1ddc348287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3476b0bef9534651b065334b363e794d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_cc271ee61d2646e9aa661b5ab944f649",
            "_dom_classes": [],
            "description": "idx_ex",
            "step": 1,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 2000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 99,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 0,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd42bb7f73664e37ac53b7c1b1c83969"
          }
        },
        "a58816bcb7234d3d996fb178c694fda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_602634f2301d457480010f61bbdd6ba5",
            "_dom_classes": [],
            "description": "pool_size",
            "step": 1,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 32,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 1,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_938718071ecf4928ba7ff32d303b599b"
          }
        },
        "8e9b6a5471164ae1ba2890e24caf8a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_8e8df5c0335f42f49cb77ebc80681d92",
            "_dom_classes": [],
            "description": "pool_stride",
            "step": 1,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 1,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fe4d3a012b44752b64a087dc26849af"
          }
        },
        "279a9e26cf234d4ea2b9fde2432b40ab": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": [],
                  "needs_background": "light"
                },
                "image/png": "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\n",
                "text/plain": "<Figure size 432x288 with 6 Axes>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_9d92e6e0a8b044bfb12beb9c82d70268",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "cc271ee61d2646e9aa661b5ab944f649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd42bb7f73664e37ac53b7c1b1c83969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "602634f2301d457480010f61bbdd6ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "938718071ecf4928ba7ff32d303b599b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e8df5c0335f42f49cb77ebc80681d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fe4d3a012b44752b64a087dc26849af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d92e6e0a8b044bfb12beb9c82d70268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB4xzFEzubr3",
        "colab_type": "text"
      },
      "source": [
        "# Trabalho de IA - Relatorio\n",
        "Neste notebook iremos descrever as decisões tomadas em cada submissão do trabalho, e mostrar os seus resultados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev25ewXBsNWe",
        "colab_type": "text"
      },
      "source": [
        "#Submissão inicial:\n",
        "Tinhamos como objetivos buscar entender os dados do dataset CIFAR 10, e predizer um conjunto de teste com uma acurácia relativamente melhorada. Inicialmente tinhamos uma acurácia de 0.1925 para melhorar este número, modificamos o conjunto de dados, apagando as colunas láterais com o objetivo de visualizar os pixels mais centralizados de cada imagem, e assim obtivemos uma acurácia de 0.2275, com isso um pouco melhor que a anterior.\n",
        "\n",
        "Antes de optarmos por essas modificação, fizemos um teste. Fizemos um drop na ultima coluna, para assim verificamos as mudanças que eram feitas na imagem. Nesse teste obtivemos acurácia 0.19, sendo essa pior que a original.\n",
        "\n",
        "Observação: Em ambos os testes utilizamos a mesma técnica de validação, hold-out.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA80gZyysQCy",
        "colab_type": "text"
      },
      "source": [
        "`Antes da modificação`\n",
        "\n",
        "![Antes da modificação](https://drive.google.com/uc?id=1rHHfnVqz7nY17tLoX9Vu2ZDGsYuG5SSU)\n",
        "\n",
        "`Depois da modificação`\n",
        "\n",
        "![Antes da modificação](https://drive.google.com/uc?id=1NUohEg6c-GB79FlGQtgxj5gAUlJdcbjB)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPYaIkAcsTQv",
        "colab_type": "text"
      },
      "source": [
        "#Submissão preliminar\n",
        "\n",
        "Na submissão preliminar optamos por conhecer os atributos da LogisticRegression e então manipulalos para melhorar o resultado da acurácia. Fizemos uma pesquisa na documentação do sklearn, onde encontramos a descrição de cada atributo, a partir disso optamos por modificar o atributo **C**.\n",
        "\n",
        "Com base na documentação: **C** é um float, opcional, com padrão igual a 1.\n",
        "\n",
        "*Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.*\n",
        "\n",
        "Então fomos calibrando até **C** = 0.03, o primeiro teste foi sem apagar colunas, ainda usando a técnica de validação hold-out, onde manipulamos os atributos **train_size **  com valor 0.3 e **random_state** **com o valor 42**.\n",
        "\n",
        "Segundo a documentação:\n",
        "\n",
        "train_size: *If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the test size.*\n",
        "\n",
        "random_state: *If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.*\n",
        "\n",
        "Com isso obtivemos acurácia: 0.315\n",
        "\n",
        "Usando outra técnica de validação cross_val_score, também sem apagar colunas do conjunto de dados, com atributos da seguinte forma:\n",
        "\n",
        "**scores = cross_val_score(pipeline, x, y, cv=5)**\n",
        "\n",
        "Score: 0.2704\n",
        "\n",
        "Observamos uma variação da acurácia para o socore calculado, buscamos entender qual seria o erro, mas encontramos dificuldades nesse aspecto, continuamos manipulando os atributos, tanto da regressão quanto da técnica de validação. Passamos a utilizar o cross_val_score após essas dificuldades encontradas, assim conseguimos obeservar melhor os resultados dos testes.\n",
        "\n",
        "A partir desse ponto modificamos o conjunto de dados, apagando algumas colunas, com o drop das 3 primeiras e 3 últimas colunas obtivemos uma acurácia 0.323333 e score 0.26999\n",
        "\n",
        "`Sem apagar as colunas`\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1p16fngGPIyY07G4JgqdX3HKPBlfHX0ZD)\n",
        "\n",
        "`Apagando as colunas`\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1JHQCqnh_DzfDELdLGtA-5X1C0JZwhCfM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7EwjY7WuiyH",
        "colab_type": "text"
      },
      "source": [
        "# Submissão final\n",
        "\n",
        "Na última submissão utlizamos as técnicas de convolução e pooling.\n",
        "\n",
        "Baseando-se somente no score, pois a técnica utilizada é mais robusta que hold-out. Dessa forma teremos uma melhor avaliação de nossas escolhas. Começamos apenas testando a utilização da convulação e pooling com a modificação dos mesmos atributos citados na submissão anterior. \n",
        "\n",
        "`Teste 1 CV = 5`\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1aruD68EnMEnrBihQzYdLg5lCO_kwwJ9E)\n",
        "\n",
        "`Teste 2 CV = 12`\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=19Paxe4RZkIXtgH9rSoiUHYKgV-neZiTA)\n",
        "\n",
        "Agora teste realizados modificando os filtros. \n",
        "\n",
        "`Teste 1 `\n",
        "\n",
        "**Filtro detecta bordas** \n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1Hd6-gOOiCZFFIF1nAbsRjB_9-Qwll2tQ)  \n",
        "![alt text](https://drive.google.com/uc?id=1A2bJwUQArd9L-l7AxUFx95KGX0UiHujV)  \n",
        "\n",
        "`Teste 2`\n",
        "\n",
        "**Filtro aguçar**\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=13HDLG_LfJUzx8wRSsJmYqom73PS2HzdI)  \n",
        "![alt text](https://drive.google.com/uc?id=1e77jbWkx3EzUoxpJ17KEXa5gYzWvWEM9)\n",
        "\n",
        "`Teste 3`\n",
        "\n",
        "**Filtro desfoque**\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1Q3ju6CI6fAgKXFkkQRlwgUMeJ1CkDbxm)  \n",
        "![alt text](https://drive.google.com/uc?id=1Gdf176nhMANiDtpNjJ0nkVTIC7ALabMK)\n",
        "\n",
        "`Teste 4` \n",
        "\n",
        "**Filtro realça bordas** \n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1rBl1oWjTXdVzra7fog7WTsqGvC3F-uBs)  \n",
        "![alt text](https://drive.google.com/uc?id=1HQZ_aI4FZp5QyCdAkP74n6eNjBU4lhxt)\n",
        "\n",
        "`Teste 5` \n",
        "\n",
        "**Filtro destaca relevo** \n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1HGLdv3eRukP1XNZTGAkl9_6k4PQy9DaR)  \n",
        "![alt text](https://drive.google.com/uc?id=1zTwgnJK0Ovi6vTPXla9sHYeEwU5kvUAc)\n",
        "\n",
        "A partir de alguns testes feitos, sendo esses manipulando os atributos da convolução, pooling e aplicando novos filtros, observamos que os melhores resultados foram obtidos usando size 6 e stride 3. Testamos algumas variações nos atributos citados, mas tivemos diferença entre 0.1 e 0.3, ou seja, o score estava em torno de 0.28 a 0.30 com a mudança nos valores dos atributos. Concluindo, o melhor o resultado foi obtido ao utilizar o filtro que destaca o relevo. Em todos os testes efetuados mudamos os atributos, da **LogisticRegression**, **cross_val_score**, **pooling e convolução**, a seguir apresentamos o exemplo onde obtivemos melhor resultado, até a data proposta.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Brr129HDBjPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import colors\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact, IntSlider, fixed\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "class IdentityNormalize(colors.Normalize):\n",
        "  '''\n",
        "  Classe para desligar normalização de cores ao exibir filtros.\n",
        "  Isto permite diferenciar alguns filtros.\n",
        "  '''\n",
        "  def __call__(self, value, clip=None):\n",
        "      return value\n",
        "\n",
        "id_norm = IdentityNormalize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2b1--XbqHoN",
        "colab_type": "text"
      },
      "source": [
        "# Submissão final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBDjnWkHH5Qk",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR10\n",
        "Agora,\n",
        "obteremos os dados do trabalho \n",
        "  e aplicaremos convolução e pooling para extrair novos atributos.\n",
        "\n",
        "São disponibilizados dois conjuntos de dados:\n",
        "- [treino](https://github.com/eraldoluis/cifar10-datasets/raw/master/cifar10-train.csv.zip) - Este conjunto deve ser usado para treinamento e seleção de modelos.\n",
        "- [teste](https://github.com/eraldoluis/cifar10-datasets/raw/master/cifar10-test.csv.zip) - Este conjunto não possui a variável a ser predita, ou seja, contém apenas os atributos de entrada.\n",
        "Cada grupo deve usar seu melhor modelo para predizer as classes dos exemplos neste conjunto.\n",
        "Então,\n",
        "as classes preditas devem ser entregues no final do trabalho.\n",
        "\n",
        "A acurácia obtida por cada grupo no conjunto de teste será usada para calcular uma parte da nota do trabalho,\n",
        "  como especificado abaixo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NrBbpZVdtv2",
        "colab_type": "text"
      },
      "source": [
        "### Lista de Classes\n",
        "Abaixo criamos uma tupla com as classes do problema.\n",
        "A ordem das classes está de acordo com os IDs disponíveis nos conjuntos de dados.\n",
        "Isto é,\n",
        "a posição da classe na tupla corresponde ao ID da classe.\n",
        "Portanto,\n",
        "esta tupla `CLASSES` pode ser usada para converter um ID\n",
        "  (número inteiro entre 0 e 9)\n",
        "  para o nome da classe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNhI_wKwr10Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES = (\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
        "           \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39LL_dlCon3p",
        "colab_type": "text"
      },
      "source": [
        "### Obtendo Conjunto de Treino\n",
        "O conjunto de trieno contém 2 mil imagens.\n",
        "O conjunto de treino pode ser baixado pelo link fornecido acima.\n",
        "Entretanto, \n",
        "em princípio,\n",
        "  não é necessário salvar este arquivo na sua máquina local.\n",
        "O pandas permite a criação de um DataFrame \n",
        "  diretamente a partir de um link.\n",
        "\n",
        "Observe que a primeira coluna corresponde à classe (rótulo) do exemplo\n",
        "  e as colunas seguintes são os valores de cada um dos 1024 pixels (32 * 32).\n",
        "As colunas dos pixels estão nomeadas como `p_lin_col`,\n",
        "  sendo que `lin` corresponde à linha da imagem\n",
        "  e `col` à coluna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtbEKqNx_oJT",
        "colab_type": "code",
        "outputId": "e776a842-c493-40be-9d50-670c6f0d89d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "df_train = pd.read_csv(\"https://github.com/eraldoluis/cifar10-datasets/raw/master/cifar10-train.csv.zip\")\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>p_00_00</th>\n",
              "      <th>p_00_01</th>\n",
              "      <th>p_00_02</th>\n",
              "      <th>p_00_03</th>\n",
              "      <th>p_00_04</th>\n",
              "      <th>p_00_05</th>\n",
              "      <th>p_00_06</th>\n",
              "      <th>p_00_07</th>\n",
              "      <th>p_00_08</th>\n",
              "      <th>p_00_09</th>\n",
              "      <th>p_00_10</th>\n",
              "      <th>p_00_11</th>\n",
              "      <th>p_00_12</th>\n",
              "      <th>p_00_13</th>\n",
              "      <th>p_00_14</th>\n",
              "      <th>p_00_15</th>\n",
              "      <th>p_00_16</th>\n",
              "      <th>p_00_17</th>\n",
              "      <th>p_00_18</th>\n",
              "      <th>p_00_19</th>\n",
              "      <th>p_00_20</th>\n",
              "      <th>p_00_21</th>\n",
              "      <th>p_00_22</th>\n",
              "      <th>p_00_23</th>\n",
              "      <th>p_00_24</th>\n",
              "      <th>p_00_25</th>\n",
              "      <th>p_00_26</th>\n",
              "      <th>p_00_27</th>\n",
              "      <th>p_00_28</th>\n",
              "      <th>p_00_29</th>\n",
              "      <th>p_00_30</th>\n",
              "      <th>p_00_31</th>\n",
              "      <th>p_01_00</th>\n",
              "      <th>p_01_01</th>\n",
              "      <th>p_01_02</th>\n",
              "      <th>p_01_03</th>\n",
              "      <th>p_01_04</th>\n",
              "      <th>p_01_05</th>\n",
              "      <th>p_01_06</th>\n",
              "      <th>...</th>\n",
              "      <th>p_30_24</th>\n",
              "      <th>p_30_25</th>\n",
              "      <th>p_30_26</th>\n",
              "      <th>p_30_27</th>\n",
              "      <th>p_30_28</th>\n",
              "      <th>p_30_29</th>\n",
              "      <th>p_30_30</th>\n",
              "      <th>p_30_31</th>\n",
              "      <th>p_31_00</th>\n",
              "      <th>p_31_01</th>\n",
              "      <th>p_31_02</th>\n",
              "      <th>p_31_03</th>\n",
              "      <th>p_31_04</th>\n",
              "      <th>p_31_05</th>\n",
              "      <th>p_31_06</th>\n",
              "      <th>p_31_07</th>\n",
              "      <th>p_31_08</th>\n",
              "      <th>p_31_09</th>\n",
              "      <th>p_31_10</th>\n",
              "      <th>p_31_11</th>\n",
              "      <th>p_31_12</th>\n",
              "      <th>p_31_13</th>\n",
              "      <th>p_31_14</th>\n",
              "      <th>p_31_15</th>\n",
              "      <th>p_31_16</th>\n",
              "      <th>p_31_17</th>\n",
              "      <th>p_31_18</th>\n",
              "      <th>p_31_19</th>\n",
              "      <th>p_31_20</th>\n",
              "      <th>p_31_21</th>\n",
              "      <th>p_31_22</th>\n",
              "      <th>p_31_23</th>\n",
              "      <th>p_31_24</th>\n",
              "      <th>p_31_25</th>\n",
              "      <th>p_31_26</th>\n",
              "      <th>p_31_27</th>\n",
              "      <th>p_31_28</th>\n",
              "      <th>p_31_29</th>\n",
              "      <th>p_31_30</th>\n",
              "      <th>p_31_31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>61.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>...</td>\n",
              "      <td>87.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>97.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>173.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>136.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>255.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>...</td>\n",
              "      <td>74.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>85.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>25.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>...</td>\n",
              "      <td>100.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>179.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>...</td>\n",
              "      <td>74.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>76.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1025 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  p_00_00  p_00_01  p_00_02  ...  p_31_28  p_31_29  p_31_30  p_31_31\n",
              "0      6     61.0     45.0     48.0  ...    144.0    188.0    123.0     97.0\n",
              "1      9    173.0    135.0    104.0  ...    133.0    136.0    136.0    136.0\n",
              "2      9    255.0    253.0    253.0  ...     77.0     83.0     84.0     85.0\n",
              "3      4     25.0     34.0     35.0  ...     58.0     47.0     56.0     65.0\n",
              "4      1    179.0    177.0    185.0  ...     74.0     78.0     74.0     76.0\n",
              "\n",
              "[5 rows x 1025 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6og18xApWZB",
        "colab_type": "text"
      },
      "source": [
        "### Criando Exemplos como Matrizes 32x32\n",
        "Vamos convertes os exemplos em matrizes de 32x32 pixels\n",
        "  para facilitar o processamento com os filtros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLuyC0LsAQgl",
        "colab_type": "code",
        "outputId": "a10e0eea-fd9a-4148-f29a-4693d13b8527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x = np.array(df_train.drop(columns=[\"label\"])).reshape(-1, 32, 32)\n",
        "y = np.array(df_train[\"label\"])\n",
        "print(\"x.shape:\", x.shape)\n",
        "print(\"y.shape:\", y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape: (2000, 32, 32)\n",
            "y.shape: (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg5AbkJXPUzF",
        "colab_type": "text"
      },
      "source": [
        "### Visualizando um Exemplo\n",
        "Abaixo visualizamos um exemplo escolhido aleatoriamente\n",
        "  juntamente com sua classe.\n",
        "Incluímos um *slide* onde o usuário pode selecionar outra imagem para ser exibida.\n",
        "Esta funcionalidade é criada usando-se a função `interact(...)` dos notebooks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFpJe4n5ABot",
        "colab_type": "code",
        "outputId": "57c9af46-a857-47fe-bcda-43f21123efc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "3de0a167c0d043f5a3e598a01daf3389",
            "cd292daf8818461a8c963f73e20a7185",
            "264f6c657bc0476a96661f69d0cb555d",
            "a3e10f57c39b4ebdb9fff5d9e582ff14",
            "5147356216c34fefbb1f93a7be215b2d",
            "a24bcec2c75c4f57ab0a68677b04238f",
            "31b87a3306054039912a7b5907843bb8"
          ]
        }
      },
      "source": [
        "def plot_exemplo(idx_ex):\n",
        "  # Imagem do exemplo.\n",
        "  x_ex = x[idx_ex]\n",
        "  # Classe do exemplo (ID).\n",
        "  y_ex = y[idx_ex]\n",
        "\n",
        "  # Exibe imagem.\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.imshow(x_ex, cmap=plt.cm.gray)\n",
        "  plt.axis('off')\n",
        "  plt.title(f\"Classe: {CLASSES[y_ex]}\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Seleciona um índice aleatoriamente.\n",
        "idx_ex = np.random.choice(x.shape[0])\n",
        "\n",
        "interact(plot_exemplo, idx_ex=IntSlider(value=idx_ex, min=0, max=x.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3de0a167c0d043f5a3e598a01daf3389",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=1373, description='idx_ex', max=2000), Output()), _dom_classes=('widget-…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.plot_exemplo>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDYHC7vlU6tS",
        "colab_type": "text"
      },
      "source": [
        "## Filtros de Convolução\n",
        "Como vimos acima,\n",
        "um filtro de convolução é representado por uma pequena matriz,\n",
        "  em geral, quadrada (mesmo número de linhas e colunas).\n",
        "Abaixo, definimos um filtro 7x7.\n",
        "Logo em seguida exibimos este filtro.\n",
        "Observe que podemos usar, inclusive, valores negativos em um filtro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNcYF60ICdJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filtro = np.array([[-0.1,  0.4,  0.8,  1.,   0.8,  0.4, -0.1],\n",
        "#                   [-0.1,  0.4,  0.8,  1.,   0.8,  0.4, -0.1],\n",
        "#                   [-0.1,  0.4,  0.8,  1.,   0.8,  0.4, -0.1],\n",
        "#                   [-0.1,  0.4,  0.8,  1.,   0.8,  0.4, -0.1],\n",
        "#                   [-0.1,  0.4,  0.8,  1.,   0.8,  0.4, -0.1],\n",
        "#                   [-0.1,  0.4,  0.8,  1.,   0.8,  0.4, -0.1],\n",
        "#                   [-0.1,  0.4,  0.8,  1.,   0.8,  0.4, -0.1]])\n",
        "\n",
        "# REALÇA BORDAS SCORE: 0.310\n",
        "#filtro = np.array([[0.0,  0.0,  0.0],\n",
        " #                  [-1.,  1.,  0.0],\n",
        " #                [0.0,  0.0,  0.0]])\n",
        "\n",
        "# DESTACA RELEVO OBS: MELHOR TESTE ATÉ O MOMENTO SCORE: 0.316\n",
        "# SIZE:6 STRIDE: 3\n",
        "filtro = np.array([[-2.,  -1.,  0.0],\n",
        "                   [-1.,  1.,  1.],\n",
        "                   [0.0,  1.,  2.]])\n",
        "\n",
        "# AGUÇAR SCORE: 0.3014\n",
        "#filtro = np.array([[0.0,  -1.,  0.0],\n",
        "#                    [-1.,  5.,  -1.],\n",
        "#                    [0.0,  -1.,  0.0]])\n",
        "\n",
        "# DETECTA BORDAS SCORE: 0.3010\n",
        "#filtro = np.array([[0.0,  1.,  0.0],\n",
        "#                     [1.,  -4.,  1.],\n",
        "#                     [0.0,  1.,  0.0]])\n",
        "\n",
        "# DESFOQUE SCORE: 0.3055\n",
        "#filtro = np.array([[1,  1., 1.],\n",
        "#                    [1., 1., 1.],\n",
        "#                    [1., 1., 1.]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twMNxHxPZRwz",
        "colab_type": "text"
      },
      "source": [
        "### Visualizando Filtro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4jBQTNoNByJ",
        "colab_type": "code",
        "outputId": "fc04d50e-8558-4523-cd4d-f6b8c64c98f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "def exibe_filtro(filtro):\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.imshow(filtro, cmap=plt.cm.gray, norm=id_norm)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "exibe_filtro(filtro)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAABUUlEQVR4nO3cOQoDQQwAQcv4/1+WX+BNDHvQVakSQaNgkpndfdHwvnoBziN2iNghYoeIHSJ2yOdoODPeZQ+zu/Nr5rJDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO+TwT5W78fXmf1x2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHSJ2iNghYoeIHTK7e/UOnMRlh4gdInaI2CFih4gd8gWNTQ3wTFTD7QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AABTU5iUD--Q",
        "colab_type": "text"
      },
      "source": [
        "### Outro filtro\n",
        "Abaixo definimos outro filtro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtK7JIhzD-LT",
        "colab_type": "code",
        "outputId": "69411a88-3006-4bd9-d651-c51719821dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "filtro2 = np.zeros(shape=(3,3))\n",
        "\n",
        "for row in range(filtro2.shape[0]):\n",
        "  for col in range(filtro2.shape[1]):\n",
        "    filtro2[row,col] = 0.9 / abs(row - col) if abs(row - col) > 0 else 1.0\n",
        "\n",
        "exibe_filtro(filtro2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAABg0lEQVR4nO3csW2EQBBAUWNdE1snbUCdlIFjC93ZEYv030s3Gelrgk1mOc/zi4bv2QNwH7FDxA4RO0TsELFDXn+8P+pfdhzH7BEu9n2fPcIv27Yt795sdojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHLJ/OWR7H8aibKmOM2SNcPO3OyxjDTRXEThE7ROwQsUPEDhE7ROwQsUPEDhE7ROwQsUPEDhE7ROwQsUPEDhE7ROwQsUPEDhE7ROwQsUPEDhE7ROwQsUPEDhE7ROwQsUPEDhE7ROyQ16fHfd/vmuNf1nWdPcLFE4/6vGOzQ8QOETtE7BCxQ8QOETtE7BCxQ8QOETtE7BCxQ8QOETtE7BCxQ8QOETtE7BCxQ8QOETtE7BCxQ8QOETtE7BCxQ8QOETtE7BCxQ8QOETtkOc9z9gzcxGaHiB0idojYIWKHiB3yA6E7Gzo8dY9kAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqni5bgjGmDZ",
        "colab_type": "text"
      },
      "source": [
        "### Banco de filtros\n",
        "Nas células a seguir,\n",
        "definiremos funções que aplicam um banco de filtros\n",
        "  a uma base de imagens.\n",
        "Vamos usar os dois filtros acima como banco de filtros\n",
        "  e representaremos o banco como uma lista de filtros.\n",
        "Observe que todos os filtros do banco devem ter a mesma dimensão\n",
        "  (mesmo número de linhas e colunas)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOXjyz0rG2v4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtros = [filtro, filtro2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzjfkAaEuLGI",
        "colab_type": "text"
      },
      "source": [
        "### Convolução e Pooling\n",
        "As funções abaixo aplicam um filtro de convolução \n",
        "  em várias imagens ao mesmo tempo.\n",
        "Isto é alcançado usando a funcionalidade de *broadcasting* do numpy.\n",
        "Desta forma,\n",
        "as operações são realizadas em palelo em várias imagens\n",
        "  e isto é muito mais eficiente.\n",
        "\n",
        "A função `imgs_conv_multi(imgs, filtros, stride=1)` aplica uma lista de filtros `filtros` nas imagens `imgs`.\n",
        "Todos os filtros devem ter o mesmo tamanho\n",
        "  (mesmo número de linhas e colunas)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Pqmlz8Z5UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imgs_conv(imgs, filtro, stride=1):\n",
        "  '''\n",
        "  Aplica o filtro 'filtro' nas imagens 'imgs' usando o stride dado.\n",
        "\n",
        "  img.shape -> (num_imagens, num_rows, num_cols)\n",
        "  '''\n",
        "  # Tamanho do filtro.\n",
        "  f_rows = filtro.shape[0]\n",
        "  f_cols = filtro.shape[1]\n",
        "\n",
        "  # Tamanho da imagem resultante.\n",
        "  num_imgs = imgs.shape[0]\n",
        "  num_rows = ((imgs.shape[1] - f_rows) // stride) + 1\n",
        "  num_cols = ((imgs.shape[2] - f_cols) // stride) + 1\n",
        "\n",
        "  # Resultado da convolução.\n",
        "  res = np.zeros((num_imgs, num_rows, num_cols))\n",
        "\n",
        "  # Aplica filtro em cada posição da imagem.\n",
        "  for row in range(num_rows):\n",
        "    for col in range(num_cols):\n",
        "      r = row*stride\n",
        "      c = col*stride\n",
        "      res[:,row,col] = np.multiply(filtro, imgs[:,r:r+f_rows,c:c+f_cols]).sum(axis=(1,2))\n",
        "  \n",
        "  return res\n",
        "\n",
        "def imgs_conv_multi(imgs, filtros, stride=1):\n",
        "  '''\n",
        "  Aplica uma lista de filtros nas imagens dadas.\n",
        "  '''\n",
        "  res = []\n",
        "  for filtro in filtros:\n",
        "    res.append(imgs_conv(imgs, filtro, stride))\n",
        "  return np.stack(res).mean(axis=0)\n",
        "\n",
        "def imgs_pool(imgs, size=8, stride=8):\n",
        "  '''\n",
        "  Aplica mean-pooling nas imagens dadas usadas o tamanho (size) e o stride dados.\n",
        "  '''\n",
        "  # Tamanho da imagem resultante.\n",
        "  num_imgs = imgs.shape[0]\n",
        "  num_rows = ((imgs.shape[1] - size) // stride) + 1\n",
        "  num_cols = ((imgs.shape[2] - size) // stride) + 1\n",
        "\n",
        "  # Resultado do pooling.\n",
        "  res = np.zeros((num_imgs, num_rows, num_cols))\n",
        "\n",
        "  # Aplica filtro em cada posição da imagem.\n",
        "  for row in range(num_rows):\n",
        "    for col in range(num_cols):\n",
        "      r = row*stride\n",
        "      c = col*stride\n",
        "      res[:,row,col] = imgs[:,r:r+size,c:c+size].mean(axis=(1,2))\n",
        "  \n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzj1EvWLZ1HZ",
        "colab_type": "text"
      },
      "source": [
        "### Visualizando Convolução de Filtros em uma Imagem\n",
        "Abaixo apresentamos uma visualização do resultado da convolução dos dois filtros definidos acima,\n",
        "  combinados a uma operação de pooling.\n",
        "Novamente,\n",
        "usamos a função `interact(...)` para permitir a seleção\n",
        "  da imagem,\n",
        "  do tamanho do pooling\n",
        "  e do stride do pooling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJEJzZHZnxFM",
        "colab_type": "code",
        "outputId": "761387c2-ab14-42cf-a319-63ba60bacdf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377,
          "referenced_widgets": [
            "a2168dd69efa4892a46dc2853c816071",
            "8c93c72998534ebeb5a5be1ddc348287",
            "3476b0bef9534651b065334b363e794d",
            "a58816bcb7234d3d996fb178c694fda9",
            "8e9b6a5471164ae1ba2890e24caf8a31",
            "279a9e26cf234d4ea2b9fde2432b40ab",
            "cc271ee61d2646e9aa661b5ab944f649",
            "dd42bb7f73664e37ac53b7c1b1c83969",
            "602634f2301d457480010f61bbdd6ba5",
            "938718071ecf4928ba7ff32d303b599b",
            "8e8df5c0335f42f49cb77ebc80681d92",
            "6fe4d3a012b44752b64a087dc26849af",
            "9d92e6e0a8b044bfb12beb9c82d70268"
          ]
        }
      },
      "source": [
        "def plot_filtros_imagem(idx_ex, filtros, pool_size, pool_stride):\n",
        "  # Obtém uma matriz contendo apenas a imagem selecionada.\n",
        "  x_res = x[idx_ex:idx_ex+1]\n",
        "\n",
        "  # Aplica convolução.\n",
        "  x_conv = imgs_conv_multi(x_res, filtros)\n",
        "\n",
        "  # Aplica pooling.\n",
        "  x_pool = imgs_pool(x_conv, size=pool_size, stride=pool_stride)\n",
        "\n",
        "  # Cria array de imagens com duas linhas e uma coluna para cada filtro.\n",
        "  max_cols = max(3, len(filtros))\n",
        "  fig, axs = plt.subplots(2, max_cols, figsize=(2*max_cols, 4))\n",
        "\n",
        "  # Exibe filtros na primeira linha da imagem.\n",
        "  for idx, filtro in enumerate(filtros):\n",
        "    axs[0][idx].imshow(filtro, cmap=plt.cm.gray, norm=id_norm)\n",
        "    axs[0][idx].set_title(f\"Filtro {idx}: {filtro.shape}\")\n",
        "    axs[0][idx].axis('off')\n",
        "  \n",
        "  # Preenche imagens vazias.\n",
        "  for idx in range(3 - len(filtros)):\n",
        "    axs[0][2 + idx].axis('off')\n",
        "  for idx in range(len(filtros) - 3):\n",
        "    axs[1][len(filtros) - 1 + idx].axis('off')\n",
        "\n",
        "  # Exibe imagem.\n",
        "  axs[1][0].imshow(x_res[0], cmap=plt.cm.gray)\n",
        "  axs[1][0].set_title(f\"Classe: {CLASSES[y[idx_ex]]}\")\n",
        "  axs[1][0].axis('off')\n",
        "\n",
        "  # Exibe resultado da convolução.\n",
        "  axs[1][1].imshow(x_conv[0], cmap=plt.cm.gray)\n",
        "  axs[1][1].set_title(f\"Conv: {x_conv[0].shape}\")\n",
        "  axs[1][1].axis('off')\n",
        "\n",
        "  # Exibe resultado do pooling.\n",
        "  axs[1][2].imshow(x_pool[0], cmap=plt.cm.gray)\n",
        "  axs[1][2].set_title(f\"Pooling: {x_pool[0].shape}\")\n",
        "  axs[1][2].axis('off')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "num_imgs = x.shape[0]\n",
        "\n",
        "interact(plot_filtros_imagem, \n",
        "         idx_ex=IntSlider(value=random.randrange(num_imgs), min=0, max=num_imgs),\n",
        "         filtros=fixed(filtros),\n",
        "         pool_size=IntSlider(value=6, min=1, max=32), \n",
        "         pool_stride=IntSlider(value=3, min=1, max=16))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2168dd69efa4892a46dc2853c816071",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=99, description='idx_ex', max=2000), IntSlider(value=6, description='poo…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.plot_filtros_imagem>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRcPPsEmXwGm",
        "colab_type": "text"
      },
      "source": [
        "## Transformando Dataset\n",
        "Abaixo,\n",
        "aplicamos as operações de convolução e pooling no dataset do CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-I6TVeSwZ7Z",
        "colab_type": "code",
        "outputId": "901491f5-28ae-4613-d0bc-dc378ddd50f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Aplica convolução.\n",
        "x_conv = imgs_conv_multi(x, filtros)\n",
        "\n",
        "# Aplica pooling.\n",
        "x_pool = imgs_pool(x_conv, size=6, stride=3)\n",
        "\n",
        "# Volta para o shape com dois axis.\n",
        "x_res = x_pool.reshape((x_pool.shape[0], -1))\n",
        "\n",
        "print(x.shape)\n",
        "print(x_res.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 32, 32)\n",
            "(2000, 81)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVd5NJTuPdZw",
        "colab_type": "text"
      },
      "source": [
        "## Treinando e Avaliando um Classificador\n",
        "Agora vamos treinar um regressor logístico\n",
        "  usando os hiper-parâmetros padrão.\n",
        "Vamos utilizar hold-out para fazer a validação do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2_Cnyo8SeGM",
        "colab_type": "text"
      },
      "source": [
        "### Treinamento com Normalização de Atributos\n",
        "Abaixo,\n",
        "treinamos um regressor logístico e, antes, \n",
        "  aplicamos a normalização min-max.\n",
        "O processo de treinamento demora alguns minutos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0r72zljaH5Rm",
        "colab_type": "code",
        "outputId": "660e7b74-c263-4739-d460-179f19864c5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Normalização de atributos min-max.\n",
        "scaler = MinMaxScaler()\n",
        "# scaler = StandardScaler()\n",
        "\n",
        "# Atributos polinomiais de grau 2.\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
        "\n",
        "# Regressor logístico.\n",
        "clf = LogisticRegression(penalty=\"none\", C=0.005)\n",
        "\n",
        "# Cria um pipeline.\n",
        "pipeline = Pipeline([(\"scaler\", scaler),\n",
        "                     (\"poly\", poly),\n",
        "                     (\"clf\", clf)])\n",
        "\n",
        "# Validação hold-out.\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_res, y, test_size=0.1, random_state=42)\n",
        "\n",
        "#validação melhorada\n",
        "scores = cross_val_score(pipeline, x_res, y, cv=12)\n",
        "\n",
        "print(scores)\n",
        "\n",
        "media = sum(scores) / len(scores)\n",
        "\n",
        "print(\"Score: \", media)\n",
        "\n",
        "# Treina modelo.\n",
        "pipeline.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.2754491  0.31137725 0.29341317 0.35928144 0.32335329 0.2994012\n",
            " 0.34131737 0.34131737 0.30722892 0.34939759 0.3373494  0.25903614]\n",
            "Score:  0.3164935189861241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
              "                ('poly',\n",
              "                 PolynomialFeatures(degree=2, include_bias=True,\n",
              "                                    interaction_only=True, order='C')),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=0.005, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='none', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfuG7avHS86Z",
        "colab_type": "text"
      },
      "source": [
        "### Avalia Modelo\n",
        "Abaixo realizamos a avaliação do modelo usando *acurácia*.\n",
        "Observe que usamos o objeto pipeline para fazer a predição\n",
        "  no conjunto de validação (`x_val`).\n",
        "Isto é muito importante pois este objeto\n",
        "  inclui a normalização dos atributos\n",
        "  de acordo com os parâmetros do conjunto de treinamento\n",
        "  (valores mínimos e máximos dos atributos).\n",
        "Como os atributos do conjunto de treino foram normalizados,\n",
        "  antes de aplicar o modelo no conjunto de validação,\n",
        "  é necessário aplicar a mesma normalização.\n",
        "O objeto `MinMaxScaler`, gerenciado pelo objeto `Pipeline`,\n",
        "  armazena os dados da normalização \n",
        "  (valores min e max para cada atributo)\n",
        "  e cuida de fazer esta normalização."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA3Cq66dS7vr",
        "colab_type": "code",
        "outputId": "866b16ae-19b5-468d-c8af-688009d1331e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = pipeline.predict(x_val)\n",
        "print(\"Acurácia:\", accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia: 0.365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OyESXzGTwQ8",
        "colab_type": "text"
      },
      "source": [
        "## Submissão dos Resultados\n",
        "Para submeter os resultados de um modelo,\n",
        "  devemos calcular as predições deste modelo \n",
        "  no conjunto de teste.\n",
        "O conjunto de teste está disponível no link fornecido no início deste notebook.\n",
        "Assim como no caso do conjunto de treino,\n",
        "  não precisamos fazer o download deste arquivo,\n",
        "  pois podemos usar o pandas para criar um DataFrame\n",
        "  diretamente a partir do link."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axw6iSDTrHPB",
        "colab_type": "text"
      },
      "source": [
        "### Obtendo Dados de Teste\n",
        "Como mencionado anteriormente,\n",
        "os dados de teste não incluem os rótulos (classes) de cada exemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fWqDTNiWH5Rt",
        "colab_type": "code",
        "outputId": "1d22278e-8dc3-43dc-88f9-3175ca87c772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "df_test = pd.read_csv(\"https://github.com/eraldoluis/cifar10-datasets/raw/master/cifar10-test.csv.zip\")\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p_00_00</th>\n",
              "      <th>p_00_01</th>\n",
              "      <th>p_00_02</th>\n",
              "      <th>p_00_03</th>\n",
              "      <th>p_00_04</th>\n",
              "      <th>p_00_05</th>\n",
              "      <th>p_00_06</th>\n",
              "      <th>p_00_07</th>\n",
              "      <th>p_00_08</th>\n",
              "      <th>p_00_09</th>\n",
              "      <th>p_00_10</th>\n",
              "      <th>p_00_11</th>\n",
              "      <th>p_00_12</th>\n",
              "      <th>p_00_13</th>\n",
              "      <th>p_00_14</th>\n",
              "      <th>p_00_15</th>\n",
              "      <th>p_00_16</th>\n",
              "      <th>p_00_17</th>\n",
              "      <th>p_00_18</th>\n",
              "      <th>p_00_19</th>\n",
              "      <th>p_00_20</th>\n",
              "      <th>p_00_21</th>\n",
              "      <th>p_00_22</th>\n",
              "      <th>p_00_23</th>\n",
              "      <th>p_00_24</th>\n",
              "      <th>p_00_25</th>\n",
              "      <th>p_00_26</th>\n",
              "      <th>p_00_27</th>\n",
              "      <th>p_00_28</th>\n",
              "      <th>p_00_29</th>\n",
              "      <th>p_00_30</th>\n",
              "      <th>p_00_31</th>\n",
              "      <th>p_01_00</th>\n",
              "      <th>p_01_01</th>\n",
              "      <th>p_01_02</th>\n",
              "      <th>p_01_03</th>\n",
              "      <th>p_01_04</th>\n",
              "      <th>p_01_05</th>\n",
              "      <th>p_01_06</th>\n",
              "      <th>p_01_07</th>\n",
              "      <th>...</th>\n",
              "      <th>p_30_24</th>\n",
              "      <th>p_30_25</th>\n",
              "      <th>p_30_26</th>\n",
              "      <th>p_30_27</th>\n",
              "      <th>p_30_28</th>\n",
              "      <th>p_30_29</th>\n",
              "      <th>p_30_30</th>\n",
              "      <th>p_30_31</th>\n",
              "      <th>p_31_00</th>\n",
              "      <th>p_31_01</th>\n",
              "      <th>p_31_02</th>\n",
              "      <th>p_31_03</th>\n",
              "      <th>p_31_04</th>\n",
              "      <th>p_31_05</th>\n",
              "      <th>p_31_06</th>\n",
              "      <th>p_31_07</th>\n",
              "      <th>p_31_08</th>\n",
              "      <th>p_31_09</th>\n",
              "      <th>p_31_10</th>\n",
              "      <th>p_31_11</th>\n",
              "      <th>p_31_12</th>\n",
              "      <th>p_31_13</th>\n",
              "      <th>p_31_14</th>\n",
              "      <th>p_31_15</th>\n",
              "      <th>p_31_16</th>\n",
              "      <th>p_31_17</th>\n",
              "      <th>p_31_18</th>\n",
              "      <th>p_31_19</th>\n",
              "      <th>p_31_20</th>\n",
              "      <th>p_31_21</th>\n",
              "      <th>p_31_22</th>\n",
              "      <th>p_31_23</th>\n",
              "      <th>p_31_24</th>\n",
              "      <th>p_31_25</th>\n",
              "      <th>p_31_26</th>\n",
              "      <th>p_31_27</th>\n",
              "      <th>p_31_28</th>\n",
              "      <th>p_31_29</th>\n",
              "      <th>p_31_30</th>\n",
              "      <th>p_31_31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>...</td>\n",
              "      <td>193.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>192.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>181.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>...</td>\n",
              "      <td>91.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>97.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>183.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>...</td>\n",
              "      <td>171.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>133.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>...</td>\n",
              "      <td>163.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>137.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>165.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>197.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>...</td>\n",
              "      <td>162.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>122.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1024 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   p_00_00  p_00_01  p_00_02  p_00_03  ...  p_31_28  p_31_29  p_31_30  p_31_31\n",
              "0    187.0    187.0    187.0    187.0  ...    193.0    192.0    192.0    192.0\n",
              "1    181.0    179.0    176.0    173.0  ...     39.0     45.0    110.0     97.0\n",
              "2    183.0    179.0    180.0    184.0  ...    237.0    227.0    223.0    230.0\n",
              "3    133.0    137.0    131.0    119.0  ...    134.0    138.0    162.0    137.0\n",
              "4    165.0    157.0    146.0    129.0  ...    114.0    134.0    130.0    122.0\n",
              "\n",
              "[5 rows x 1024 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tY5FK8QBPqg",
        "colab_type": "text"
      },
      "source": [
        "### Transformando Dados de Teste\n",
        "É preciso aplicar a convolução e o pooling exatamente como foram aplicados nos dados de treino antes de usar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXHfXreIBPOY",
        "colab_type": "code",
        "outputId": "c9d7f09b-4ed8-448c-c314-78284a5f4d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Transforma em array e no formato 32x32.\n",
        "x_test = np.array(df_test).reshape((-1,32,32))\n",
        "\n",
        "# Aplica convolução.\n",
        "x_test_conv = imgs_conv_multi(x_test, filtros)\n",
        "\n",
        "# Aplica pooling.\n",
        "x_test_pool = imgs_pool(x_test_conv, size=6, stride=3)\n",
        "\n",
        "# Volta para o shape com dois axis.\n",
        "x_test_res = x_test_pool.reshape((x_test_pool.shape[0], -1))\n",
        "\n",
        "print(x_test_res.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 81)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rJZmJdPsmZ8",
        "colab_type": "text"
      },
      "source": [
        "### Predição do Modelo\n",
        "Aplicamos agora o nosso modelo nos dados do teste.\n",
        "Novamente,\n",
        "utilizamos o objeto `Pipeline` para fazer esta predição pois,\n",
        "  assim como na validação,\n",
        "  precisamos normalizar os atributos do teste de acordo com os valores\n",
        "  min e max do treino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KPcUjbuoH5R2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = pipeline.predict(x_test_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVc1xU-5tFED",
        "colab_type": "text"
      },
      "source": [
        "### Gerando Arquivo com Predições\n",
        "O arquivo de predições a ser submetido é bem simples:\n",
        "  cada linha deve conter a classe predita \n",
        "  para um exemplo do conjunto de teste.\n",
        "A ordem das predições deve seguir a mesma ordem \n",
        "  que os exemplos aparecem no arquivo de teste.\n",
        "O código abaixo gera este arquivo \n",
        "  usando a predição do modelo acima."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7T8DUxPsH5SP",
        "colab_type": "code",
        "outputId": "087f7301-bb23-4b8f-98ed-6e4029a2d233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_pred = pd.DataFrame(y_pred, columns=[\"label\"])\n",
        "df_pred.to_csv(\"cifar10-testSubmissaoFinal-predicoes.csv\", index=False)\n",
        "df_pred.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label\n",
              "0      0\n",
              "1      3\n",
              "2      6\n",
              "3      6\n",
              "4      7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvC4stPkw3lK",
        "colab_type": "text"
      },
      "source": [
        "### Download das Predições\n",
        "O código abaixo gera um download automático\n",
        "  do arquivo gerado acima.\n",
        "Talvez você tenha que autorizar este download no seu navegador.\n",
        "Este arquivo fica salvo (temporariamente)\n",
        "  no sistema de arquivos da engine do notebook.\n",
        "Você pode acessar este arquivo \n",
        "  na aba do lado esquerdo deste notebook\n",
        "  (ao lado esquerdo da tabela de conteúdo)\n",
        "  clicando em um ícone de \"pastinha\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uekhShgst4hj",
        "colab_type": "code",
        "outputId": "f13b22b2-12fb-41d8-c8f5-012c2e82ea9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"cifar10-testSubmissaoFinal-predicoes.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-370-505cdde68781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cifar10-testSubmissaoFinal-predicoes.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ0nrt84qwJR",
        "colab_type": "text"
      },
      "source": [
        "## Treinamento do Modelo Final\n",
        "Em geral,\n",
        "o desempenho de um modelo de AM aumenta \n",
        "  a medida que a quantidade de exemplos de treino aumenta.\n",
        "Desta forma,\n",
        "o ideal para alcançar o melhor desempenho\n",
        "  é treinar um novo modelo\n",
        "  em todo o conjunto de treino,\n",
        "  usando os melhores valores dos hiper-parâmetros \n",
        "  encontrados na validação cruzada.\n",
        "Você pode usar esta ideia \n",
        "  para submeter predições para o conjunto de teste."
      ]
    }
  ]
}